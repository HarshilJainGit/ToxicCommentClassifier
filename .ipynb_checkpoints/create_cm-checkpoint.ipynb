{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column header\n",
    "cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = pd.read_csv('./data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = true_labels[true_labels.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = true_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = pd.read_csv('./NBSVM_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = pred_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pred_labels[:, 0]\n",
    "ids = np.reshape(ids, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pred_labels[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.concatenate((ids, labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_df = pd.DataFrame(data=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_df = pd.DataFrame(data=pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.merge(true_labels_df, pred_labels_df, on=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.drop(all_labels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.values\n",
    "all_labels = np.array(all_labels, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cm(modelname, labels):\n",
    "    for i in range(6):\n",
    "        y_true = labels[:, i]\n",
    "        y_pred = labels[:, 6+i]\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        accuracy = (tp + tn) / (tn + tp + fn + fp)\n",
    "        filename = modelname + '_' + cols[i] + '.csv'\n",
    "        with open(filename, 'w') as f:\n",
    "            write_file = csv.writer(f)\n",
    "            write_file.writerow([tn, fp, fn, tp, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cm('NBSVM', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_average(path, modelname):\n",
    "    #files = Path(dir).glob('*.csv')\n",
    "    average = 0\n",
    "    for i in range(6):\n",
    "        file = Path(path).joinpath(modelname + '_' + cols[i] + '.csv')\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        result = df.values.flatten()\n",
    "        average += result[4]\n",
    "    average /= 6\n",
    "    filename = Path.cwd().joinpath('average_NBSVM.csv')\n",
    "    with open(filename, 'w') as f:\n",
    "        f_write = csv.writer(f)\n",
    "        f_write.writerow([average])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_average('./', 'NBSVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "labels = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('./data/train.csv')\n",
    "#nonempty = labels[~np.all(labels == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty = labels[~np.all(labels == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16225\n"
     ]
    }
   ],
   "source": [
    "print(len(nonempty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_and_recall(modelname, labels, path):\n",
    "    for i in range(6):\n",
    "        y_true = labels[:, i]\n",
    "        y_pred = labels[:, 6+i]\n",
    "        filename = path + modelname + '_' + cols[i] + '.csv'\n",
    "        with open(filename, 'r') as file:\n",
    "            write = csv.writer(file)\n",
    "            df = pd.read_csv(filename, header=None)\n",
    "            #result = df.values.ravel()\n",
    "            tn, fp, fn, tp, accuracy = df.values.ravel()\n",
    "            tpr = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            tnr = tn / (tn + fp)\n",
    "            balanced_accuracy = (tpr + tnr) / 2\n",
    "        with open(filename, 'a') as f:\n",
    "            write_file = csv.writer(f)\n",
    "            write_file.writerow([tpr, recall, balanced_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_precision_and_recall('NBSVM', all_labels, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_avg_acc(modelname, path):\n",
    "    sum_average = 0\n",
    "    for i in range(6):\n",
    "        filename = path + modelname + '_' + cols[i] + '.csv'\n",
    "        with open(filename, 'r') as file:\n",
    "            write = csv.writer(file)\n",
    "            df = pd.read_csv(filename, header=None)\n",
    "            result = df.iloc[[1]].values.ravel()[2]\n",
    "            sum_average += result\n",
    "    sum_average /= 6\n",
    "    save_file = path + 'average_' + modelname + '.csv'\n",
    "    with open(save_file, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([sum_average])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_avg_acc('NBSVM', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def cal_log_loss(modelname, labels, path):\n",
    "    average_log_loss = 0\n",
    "    for i in range(6):\n",
    "        y_true = labels[:, i]\n",
    "        y_true = np.array(y_true, dtype=np.int8)\n",
    "        y_pred = labels[:, 6+i]\n",
    "        filename = path + modelname + '_' + cols[i] + '.csv'\n",
    "        average_log_loss += log_loss(y_true, y_pred)\n",
    "    average_log_loss /= 6\n",
    "    save_file = path + 'average_' + modelname + '.csv'\n",
    "    with open(save_file, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([average_log_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_log_loss('NBSVM', all_labels, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "def cal_hamming_loss(modelname, labels, path):\n",
    "    average_log_loss = 0\n",
    "    for i in range(6):\n",
    "        y_true = labels[:, i]\n",
    "        y_pred = labels[:, 6+i]\n",
    "        filename = path + modelname + '_' + cols[i] + '.csv'\n",
    "        average_log_loss += hamming_loss(y_true, y_pred)\n",
    "    average_log_loss /= 6\n",
    "    save_file = path + 'average_' + modelname + '.csv'\n",
    "    with open(save_file, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([average_log_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_hamming_loss('NBSVM', all_labels, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
